Received: from postoffice2.mail.cornell.edu (postoffice2.mail.cornell.edu [132.236.56.10])
	by sundial.cs.cornell.edu (8.11.3/8.11.3/M-3.10) with ESMTP id gACI1xQ12858
	for <egs@cs.cornell.edu>; Tue, 12 Nov 2002 13:01:59 -0500 (EST)
Received: from sangeeth.cornell.edu (syr-24-58-36-135.twcny.rr.com [24.58.36.135])
	by postoffice2.mail.cornell.edu (8.9.3/8.9.3) with ESMTP id NAA07618
	for <egs@cs.cornell.edu>; Tue, 12 Nov 2002 13:01:54 -0500 (EST)
Message-Id: <5.1.0.14.2.20021112125455.033eda00@postoffice2.mail.cornell.edu>
X-Sender: sc329@postoffice2.mail.cornell.edu (Unverified)
X-Mailer: QUALCOMM Windows Eudora Version 5.1
Date: Tue, 12 Nov 2002 13:01:54 -0500
To: egs@CS.Cornell.EDU
From: Sangeeth Chandrakumar <sc329@cornell.edu>
Subject: 615 PAPER 63
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"; format=flowed


submitted by sangeeth Chandrakumar

The paper on the small-phenomenon presents an algorithmic perspective to 
the principle that we are all linked by short chains of acquaintances. Over 
many trials, it was shown that the average number of intermediate steps in 
a successful chain from any arbitrary source to any destination lies 
between five and size, a quantity which is popularly referred to as the 
"six degrees of separation". In the paper, this theory has been associated 
with decentralized networks. It has been proven that form random graph 
theory, with high
probability there exists between every pair of nodes whose lengths are 
bounded by a polynomial in log N. The main contribution of the paper is 
that, there is a correlation between local structure and long-range 
connections provides fundamental cures for finding paths through the 
network. When the correlation is near a critical threshold, the structure 
allows individuals to guide a message
efficiently towards a target. As the correlation drops below a value, the 
model still have short chains in between, but the individuals are unable to 
find them.

The performance paper tries to quantity the p2p system sin terms of 
bandwidth, latency, fault tolerance capability and scaling abilities.
Computer networks bears a strong resemblance to social networks and can be 
represented by graphs in a similar way. This paper explains the general 
graph theory and correlates the performance of freenet and gnutella to a 
small-world model. Two important characteristics of a graph is its 
pathlength and clustering coefficient. In a uniform graph mode, the 
pathlength is order of N and the clustering coefficient is also high as 
most of the nodes connected by its neighbors are also connected to the 
given node. In a random graph, however the pathlengths becomes proportional 
to the logarithmic value and the clustering coefficient is also shown to 
have a low value.

Freenet's routing is depth oriented, that is it is depends on the 
neighbor's routing tables to send a query to its destination. Simulations 
indicae that freenet networks do evolve small world characteristics. From a 
uniform model. by randomly adding a few links, the freenet network is shown 
to show characteristics of random graph. Freenet has good average 
performance  but poor worst case performance. The results holds good, when 
the number of nodes increases. The network is shown to have good fault 
tolerant capability till 30 % of all nodes
fail. But a random characteristic, in which a few nodes remain highly 
connected, makes the network succeptible to attacks on nodes.

Gnutella queries perform a breadth-first search on the network graph. So it 
is neccessary that the network graph is connected for the request to 
eventually reach some peer having the desired data. A random model gnutella 
network is also shown to have to small world characteristics. Moreover 
gnutella is shown to respond equally to failure and attack. But gnutella 
scales linearly with increasing number of nodes.

Modifying a pure decentralized network to a partly heirarchical structure 
is shown to exhibit better properties in terms of both scalability and with 
respect to path lengths.

The third paper performs an evaluation of gnutella and napster network for 
characteristics such as bandwidth bottlenecks, IP-level latency, node 
availability, degree of co-operation. The measurements were done done using 
a network crawler for a few days time on each set of peers. They came up 
with the following observations:
1. a peer tends to have higher downstream than upstream bandwidth. Gnutella 
users tend to have higher downstream bottleneck than napster users, 
probably due to the fact that more gnutella users are tech savvy having 
better links to internet.
2. In a p2p system, where connections are forged in an ad-hoc way, a 
substantial fraction of connections will suffer form high latency.
3. The median availability of users was found to be 60 minutes.
4. Substantial number of "free-riders" exists in both the networks.
5. Although highly resilient in the face of random breakdowns, gnutella is 
vulnerable in the face of well orchestrated, targeted attacks.

So well designed p2p system should take the following into consideration:
- p2p systems should delegate different degrees of responsibility to 
different hosts, based on hosts physical characteristics and the degree of 
trust.
- a robust system should attempt to directly measure the physical 
characteristics of peers in the system.
- a robust system should account for the hosts heterogenity, relying on 
self-inspection and adaptation to exploit the differences in the hosts

characteristics.

