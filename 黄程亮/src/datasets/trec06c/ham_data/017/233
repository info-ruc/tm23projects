Received: from SOUTH-STATION-ANNEX.MIT.EDU by po8.MIT.EDU (5.61/4.7) id AA21984;
 Tue, 2 Jun 98 23:35:40 EDT
Received: from MIT.EDU (SOUTH-STATION-ANNEX.MIT.EDU [18.72.1.2])
        by aleve.media.mit.edu (8.8.7/ML970927) with SMTP id XAA01894
        for <babbage@media.mit.edu>; Tue, 2 Jun 1998 23:35:37 -0400 (EDT)
Received: from MIT.MIT.EDU by MIT.EDU with SMTP
        id AA20394; Tue, 2 Jun 98 23:35:27 EDT
Received: from QUODLIBET.MIT.EDU by MIT.MIT.EDU (5.61/4.7) id AA06486; Tue, 2 Ju
n 98 23:35:31 EDT
Message-Id: <3.0.32.19980602233403.0089a5f0@po8.mit.edu>
X-Sender: eboyden3@po8.mit.edu
X-Mailer: Windows Eudora Pro Version 3.0 (32)
Date: Tue, 02 Jun 1998 23:34:04 -0400
To: babbage@media.mit.edu
From: Edward Boyden <eboyden3@MIT.EDU>
Subject: Some tough problems
Cc: eboyden3@MIT.EDU
Mime-Version: 1.0
Content-Type: text/plain; charset="us-ascii"

These problems range from the simple to the incredibly ill-posed. Half of
them are looking for people to ask the questions in the right way, a third
are ready to become PhD theses, and the remaining 1/6 are interesting,
tractable, and ready for discussion. Some of these problems are more
information-theory (IT) than physics of computation (POC). WARNING: some of
these are a little disorganized. I just scribbled everything I could think
of for 20 minutes.

I have a lot more but I tire of typing.

--------Begin physica--------

What computation can be done with passive elements (Yael's problem)? what
reversible computation (e.g., no resistors or dissipative elements)? What
linear computation (no transistors etc.)? What computation can be done with
ignorant elements (e.g., cars going through intersections all over U.S.A.,
people flushing toilets at random, etc.)? What computation can be done by
hidden elements (conspiring to keep info hidden -- e.g., unwitting voters,
etc.)?

Zero-sum proofs: how can one accomplish computation in a system which
conspires to prevent computation in the component parts but wishes to
accomplish computation altogether? See the later problem on bandwidth for a
more precise version of this problem.

The game of Hex can be solved by minimizing a potential. Does this apply to
any other common physical systems? What characteristics of a computation
problem lend itself to being represented by something as mundane as a
potential? What are the characteristics of vector-systems like that? Can
one invent couplings between potentials/generalize gauge invariance to such
problems? Given a gauge symmetry, how does this affect the computational
power of a system? (Recall that local symmetries cannot have long-range
order, so a gauge symmetric hopfield net would be doomed!!)

Speaking of symmetries, do symmetries affect/enable/hamper computation?
Symmetry = conservation = Emmy Noether's equations (Hamiltonian) =
invariance = ...so they affect dynamics, which we concluded to be essential
to computation. One loses DOFs with symmetry -- so can symmetry constraints
temporarily remove Turing-completeness from dynamical systems??

Consider the 2-D system of random walks on a lattice. The correlation goes
like the number of paths, with a weight for each path. What is the mutual
information between two spins? What is the bandwidth/rate of communication
between two spins? Can one do a cumulant/cluster expansion of information
flow in a network of agents? Can one perform information flow on a Hopfield
network as well, which is essentially the same thing given an energy term?
What does this say about the computational power of a Hopfield model? What
about more general neural networks? Information flow in Bayes nets? Can one
visualize this information flow in neurological contexts? What about
quenched randomness/random bonds/Ising model?
        One strategy: information flow from a to b via c is equal to to the mutual
information between c and b, minus the mutual information between a and c
during the last time step, etc.... or transfer matrices, renormalization
group, approximations (NvL, MigdalK, duality, etc.). Phase transitions,
complexity, computational power/intractability? Proving the possibility of
computation in certain self-organizing systems?
        Essential to computation is nonlinearity, and therefore storage. Discuss
ways to store bits. How might one store a qubit for extended periods of
time? How does holographic memory work? RSFQ? Erbium light amplifiers?
Photon switches/bandgap materials? What are Arias, Joannopolous, Kardar,
and Draper Labs doing? How can one make a billion $ off of this?

Control/prediction/filtering for linear and nonlinear systems... what
strategies work? How do creatures process things? What about behaviors:
bipedal gaits, flies riding bicycles, children learning language, etc. Can
we 'program' an array of flies to do something useful? How much processing
is done per fly as the number of flies goes to infinity?

Can one find physical models for searching? Photons cascading down a
molecule? Quantum mechanics? Agents/parallelism/etc.? What natural
structures lend themselves to parallelism? There must be rapid
communication, isolation (for storage), and yet some form of readout... it
would be nice to write down some design specs for computation systems.

Positive feedback: that's what made the weak forces (10^-14 eV!!) powerful
enough to make our proteins left-handed. Given infinite time (i.e.,
evolutionary scale), how efficient is the propagation of tiny energies?
Given energies at all scales (e.g., a spectrum), how does this affect the
development of complexity at all scales? What is the effective computation
performed, per unit time, over VERY long time scales (e.g. age of the
universe)? Assume constant energy flux in -- e.g., sun rays etc.

Quantum recursion theory: make it well-posed. What happens to the halting
problem? What happens to the Turing degrees, the hierarchies? What problems
are BQP? What problems are provably beyond BQP? How can one modify
Benioff's definition of quantum turing machine to make it better posed,
especially with respect to the halting problem?

Show that three degrees of freedom of a dynamical system are enough to give
it Turing completeness. (!!!) (Moore's famous paper) Can it be done with
two? with one? Why or why not? Discuss ergodicity, nonlinearity, etc. What
happens if we replace the discrete system by the continuous, or vice versa?
What if we use a quantum dynamical system - what is the minimal number of
DOFs now?

Bayes nets, probability graph models: what physical systems lend themselves
to this unique combination of local 'concept' storage and global energy
minimization? Can DNA attached to magnets make the ultimate AI machine?

Joe J's tiny Ising spins: build a magnetic computer; solve Deutsch-Josza.
Investigate individual domain effects. How can one address tiny classical
spins?

Consider a group of agents with bandwidth w. How does this limit the rate
at which computation can be accomplished? What behaviors (say, if they are
mobile and the bandwidth depends on distance) should they exhibit to
accomplish the most computation? How can they solve searches, etc.
optimally - i.e., the nodes of a travelling salesman graph, how can they
communicate with one another in order to solve their collective problem?
What have people done with distributed architectures/parallel computers?
There are two views -- the Minksy/Maes/Media
Lab/agents/interactive/community view, and the
Intel/IBM/teraflop/CILK/Leiserson/Knight/Sussman view.

Discuss the game of go. Why is it hard? go is PSPACE-complete; prove a
similar theorem for chess (if possible). (There is a million dollar prize
to anyone who can write a go computer program, running on any platform,
that can beat an intermediate-level rated (i.e., not that good!) 12-year
old player of the offerer's choice.)

(Weiss) Researchers are now designing lasers that have no vacuum coupling,
simply because the geometry of the enclosure is such that there is no
radiation field inside to couple to. Therefore there is no spontaneous
emission inside the enclosure: only the Einstein A coefficients survive.
Can one design, say the Johnson-noise free diode perpetual motion machine
in such a cavity? Why not? (Is algorithmic complexity or Heisenberg
uncertainty the stronger argument?) What are the implications for the
algorithmic complexity of the spin echo (Lloyd, Zurek) and other simple
systems?

Integrate theoretical models of algebra with the dominant views of linear
systems. (Bring together the abstract and the concrete.) Integrate the
differential geometry/conventional
Bayes-frequentist-variational-information theoretical-etc. approaches to
information theory. Unitary operators can only shift the weights of
eigenvectors; what kinds of computation can be done this way? (Grover's
inversion about the average is sterotypical.)

Grover is optimal, e.g. square root speedup is all one can expect for
oracle problems in BQP-class quantum computers. What about partial-oracle
problems ("gray boxes")? What are partial oracles? Did Ed Boyden really
just make up that term a few minutes ago because it sounded too damn cool?
Can someone make the idea more precise?

Lie groups and manifolds and algebraic geometry... what does Freedman have
to say? What does Witten have to say? What are braid groups, TQFTs, knots,
and Conway polynomials? what does all this have to do with NP-completeness?
Could we perform quantum calculations by sending photons in orbit around
black holes?? (Kaufmann's knot theory book, Shapiro/Teukolsky's compact
object book, Los Alamos TQFT archives, John Baez' TQFT stuff).

Readout of a quantum system means that only global properties of a quantum
computation can be read by the world. What interesting problems lend
themselves to global information? What are the "local methods" used to
solve NP-completeness, and how can these be implemented on a QC? How can
one simulate a system of 200 qubits (!!) like Tad Hogg did on his PC?

Is there a cheaper way to make arbitrary computations reversible besides
Bennett's 4-step process? What about if we only consider log-space
computations? polynomial computations? Linear computations (a nice special
case: vector space embedding)? What does reversibility look like in
recursion theory? How does one implement computation histories in recursion
theory?

Quantum logic: what tautologies of classical logic are false in quantum
logic? Can quantum logic appear near-classical in the low-hbar, large mass
limit? How would a Hilbert-space computer work? What does noncommutative
algebra have to do with quantum logic? How can braids and anyons help? (von
Neumann, Svozil, Baez, U. Penn).

Control theory: how does the Julier-Uhlmann replacement for the extended
kalman filter work? Why does taking the square root of a matrix replace
random sampling? Can one extend this method to higher moments/cumulants?
How does this help one avoid taking the Jacobian of the nonlinear system?


Consciousness: what *really* happens to Schrodinger's cat? What are the
implications for Everett's many-worlds hypothesis? GellMann (in Zurek's
book, 1989) claims that Schrodinger's cat really could be dead AND alive
(superposed) -- what are the constraints for avoiding decoherence? How does
one kill the vacuum mode (see above)?

Matrix form of recursion theory? More explicit form of the mu-function?
Physical form of the fixed-point theorem? What do Post's problem and other
contrived languages mean for computers? What finite recursive axiom schema
are neither recursive nor Turing complete? (I'll solve this at Babbage II.)

What does dynamics have to do with all this? Local linearization, dimenion,
chaos, etc. - what does any of that have to do with computation anyway?
Nonlinearity (dynamics) = halting problem = chaos = etc. Moore's theorem
(PRL 64, 20, p. 2354-2357) -- can it be generalized? Do any physical
systems emulate Moore's 'toy' CA system?

What is time-space duality? How can I trade time for space or precision or
some other resource? What is the cost of one resource in terms of another?
Which resources are extensive/subextensive/exponetial in computing power?
Discuss NP/P/NL/L/PSPACE/NPSPACE/hierarchies, etc.

GENERAL PROBLEMS
Given any of the above or other questions, construct a toy physics problem
or simulation thereof to justify it.

Given physical methods -- perturbation theory, variational methods,
expansions of any kind, duality mappings, etc. -- calculate the information
etc. that is revealed through each iteration. How is this related to the
Kolmogorov entropy due to the time-evolution of chaotic Hamiltonian systems?

---------------------------------------------------------------
 edward boyden  eboyden3@mit.edu  http://web.mit.edu/eboyden3/
 617 225 8279        410 memorial dr.       cambridge ma 02139
              life is the art of answering the right questions
    the world is your playground. play with a sense of destiny
                         what a long strange journey it's been
