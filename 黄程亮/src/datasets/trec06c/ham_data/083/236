Received: from postoffice.mail.cornell.edu (postoffice.mail.cornell.edu [132.236.56.7])
	by sundial.cs.cornell.edu (8.11.3/8.11.3/M-3.10) with ESMTP id g8OFuSh01769
	for <egs@cs.cornell.edu>; Tue, 24 Sep 2002 11:56:28 -0400 (EDT)
Received: from cornell.edu (dhcp226.libecafe-dhcp.cornell.edu [128.253.117.226])
	by postoffice.mail.cornell.edu (8.9.3/8.9.3) with ESMTP id LAA24482
	for <egs@cs.cornell.edu>; Tue, 24 Sep 2002 11:56:28 -0400 (EDT)
Date: Tue, 24 Sep 2002 11:56:27 -0400
Mime-Version: 1.0 (Apple Message framework v546)
Content-Type: text/plain; charset=US-ASCII; format=flowed
Subject: 615 Paper 19
From: Milo Polte <mp98@cornell.edu>
To: egs@CS.Cornell.EDU
Content-Transfer-Encoding: 7bit
Message-Id: <2F03AA56-CFD6-11D6-8593-003065EE5F0A@cornell.edu>
X-Mailer: Apple Mail (2.546)

In this paper the authors design an ad-hoc routing algorithm to provide 
some measure of confidence in bandwidth assurances (Quality of 
Service). To reduce bandwidth, most topographical updates and bandwidth 
changes are broadcasted only towards key nodes in the network (those 
positive increases in bandwidth are advertised globally) a feature 
which is achieved through the maintenance of a vertex covering subset 
of the graph (the core). All the nodes in the core maintain total 
knowledge bandwidth
on local links and partial knowledge of high bandwidth on other parts 
of a network.

This paper is notable in that it is the first one we've looked at with 
QoS assurances, though not guarantees and real elitism in routing 
decisions (that is, certain nodes are more responsible for it then 
others). The presence of both simulation and implementation are 
impressive and while they suffer from all the typical foibles (i.e. 
there's no real network model to their simulation, their entire 
algorithm assumes bidirectional links, etc.) it is rigorous in many 
regards (e.g. one appreciates an explicit section on the effects of 
link failure).

However some omissions are unforgivable: For example, they mention 
'time complexity' in their performance measurements, but are actually 
just measuring seconds this particular case took, which is a 
measurement contingent to particular circumstances. Also while they say 
that their algorithm calculates a close to minimum core set, I would 
like to see a proof of its efficiency (or even a citation).

